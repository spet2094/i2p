Theme: casa notes
Palette: Purple
Size: Wide
Title: File Formats
Author: Jon Reades

---

Layout: Title

# Dimensionality

## Curse and Blessing...

---

Consider:

- More dimensions means more information about a process (yay!).
- More dimensions makes is easier to separate observations (yay! clustering!).
- More dimensions inflates inter-observational distance measures (using Euclidean measures).
- More dimensions increases the risk of overfitting (particularly with more features than observations!)

Or as [this site](https://analyticsindiamag.com/curse-of-dimensionality-and-what-beginners-should-do-to-overcome-it/) puts it:

- High-dimensional spaces have geometrical properties that are counter-intuitive and far from the properties observed in two- or three-dimensional spaces.
- Data analysis tools are often designed with intuitive properties and low-dimensional spaces in mind.

---

Layout: SectionTitle

## Dimensionality Reduction

---

### PCA

Workhorse dimensionality reduction method: simple, fast, and effective. Can be thought of as freely rotating axes to align with directions of maximum variance.

I like this summary:

> PCA (Principal Components Analysis) gives us our ideal set of features. **It creates a set of principal components that are rank ordered by variance** (the first component has higher variance than the second, the second has higher variance than the third, and so on)**, uncorrelated, and low in number** (we can throw away the lower ranked components as they contain little signal).

---

### In Practice...

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(data)
print(pca.explained_variance_ratio_)
print(pca.singular_values_)
pca.transform(data)
```

See also: [Kernel PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA) for non-linear problems.

---

### t-SNE



---

### UMAP

Promising alternative to PCA that supports non-linear reduction while preserving topological structure. Not currently installed in Docker/Vagrant, but available under `umap-learn` (`conda install -c conda-forge umap-learn`). See examples on [umap.scikit-tda.org](https://umap.scikit-tda.org/parameters.html).

![](https://umap.scikit-tda.org/_images/SupervisedUMAP_22_1.png)

---

### Gotcha!

Both t-SNE and UMAP require very careful handling:

1. Hyperparameters matter
2. Cluster size means nothing
3. Cluster distances mean nothing
4. Clusters may mean nothing (low neighbour count/perplexity)
5. Outputs are stochastic (*not* deterministic)

---

### Other Approaches

- Feature selection (`sklearn.feature_selection` [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection))
- Decomposition (`sklearn.decomposition` [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition))
- Other types of manifold learning (`sklearn.manifold` [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold))
- Random projection (`sklearn.random_projection` [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.random_projection))
- Support Vector Machines (`sklearn.svm` [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm))

---

## Resources

- Shapiro, W. and Yavuz, M. (2017) Rethinking 'distance' in New York City *Medium* [URL](https://medium.com/topos-ai/rethinking-distance-in-new-york-city-d17212d24919)
- Five Boroughs for the 21$^{st}$ Century *Medium* [URL](https://medium.com/topos-ai/five-boroughs-for-the-21st-century-8da941f53618)
- [Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)
- [The Curse of Dimensionality](https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e)
- [Understanding PCA](https://towardsdatascience.com/understanding-pca-fae3e243731d)
- [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)
- [How to tune the Hyperparameters of t-SNE](https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868)
- [Understanding UMAP](https://pair-code.github.io/understanding-umap/) (Compares to t-SNE)
- [UMAP for Dimensionality Reduction](https://www.youtube.com/watch?v=nq6iPZVUxZU) (Video)
- [A Bluffer's Guide to Dimensionality Reduction](https://www.youtube.com/watch?v=9iol3Lk6kyU) (Video)